---
title: "Hamaker et al. RI-CLPM"
author: "John Flournoy"
date: "September 28, 2017"
output: 
  md_document:
    toc: true
references:
- id: Hamakercritiquecrosslaggedpanel2015
  type: article-journal
  title: A critique of the cross-lagged panel model
  container-title: Psychological Methods
  page: 102-116
  volume: '20'
  issue: '1'
  source: APA PsycNET
  DOI: 10.1037/a0038889
  ISSN: 1939-1463(Electronic);1082-989X(Print)
  author:
    - family: Hamaker
      given: Ellen L.
    - family: Kuiper
      given: Rebecca M.
    - family: Grasman
      given: Raoul P. P. P.
  issued:
    date-parts:
      - - 2015
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Critique of Cross-lagged pannel models

This post summarizes critiques of the traditional cross-lagged panel model (CLPM), and an improved model by Hamaker, Kuiper, and Grasman  [-@Hamakercritiquecrosslaggedpanel2015].

The primary point Hamaker and colleagues make regarding the CLPM is that it assumes that there are "no trait-like individual differences that endure." That is, looking at the structure of a CLPM it is clear that individual-level stability must be accounted for entirely by the auto-regressive path between waves. As they put it, it imposes an assumption that there is no between-subject variance of time-invariant, trait-like stability, but only temporal stability, wave to wave, of subjects around the mean score for any particular wave.

# RI-CLPM

A key insight of the paper is that "we need to separate the _within-person level_ from the _between-person level_" (p. 104). The model they propose, the Random Intercept CLPM (RI-CLPM) separates each person's score on a variable at each wave into the group mean for that wave ($\mu_{t}, \pi_{t}$), an individuals stable score over all waves (the random intercept; $\kappa_{i}, \omega_{i}$) and then an individual level deviation at each wave from the score expected by adding the group-wave-mean and individual trait ($p_{it}, q_{it}$).

The model looks like this:

![RI-CLPM Diagram](hamaker-diagram.png)

Effectively, now, the paths $\alpha_{t}$ (or $\delta_{t}$) between $p_{it}$ (or $q_{it}$) and $p_{i(t+1)}$ (or $q_{i(t+1)}$) no longer capture rank-order stability of individuals, but rather a within-person carry-over effect.

>If it is positive, it implies that occasions on which a person scored above his or her expected score are likely to be followed by occasions on which he or she still scores above the expected score again, and vice versa. (p. 104)

More importantly, since $\kappa$ and $\omega$ separate out individual-level stability, the cross-lagged paths $\beta_{t}$ and $\gamma_{t}$ are now straightforward to interpret as the within person of effect of one variable on the subsequent measurement of a second variable. This interpretive boost is allowed now because, for example, $\beta_{t}$ is the estimate of the additional explanatory power of _deviations from trait-stable levels_ on variable $y_{t}$ on the _deviations_ of the observed variable $x_{t+1}$ from the group mean and individual trait ($\mu_{t+1} + \kappa_{i}$) after accounting for the expected within-person carry-over effect, $\alpha_{t}$. 

See the paper (Figure 2) for a demonstration of how terribly traditional CLPM performs when you have a data generating process that matches the RI-CLPM -- that is, when you have stable individual differences.

# Implemmenting the RI-CLPM in R

First, we need some data

```{r, lavaan demo growth data, message = F, warning = F}
#install.packages('lavaan')
require(lavaan)
require(tidyverse)
data("Demo.growth")

knitr::kable(summary(Demo.growth))

Demo.growth %>%
  mutate(pid = 1:n()) %>%
  gather(key, value, -pid, -x1, -x2) %>%
  extract(col = key, into = c('var', 'wave'), regex = '(\\w)(\\d)') %>%
  ggplot(aes(x = wave, y = value, color = var, group = var)) +
  geom_point(position = position_jitter(w = .2), alpha = .1) +
  geom_line(stat = 'identity', aes(group = interaction(var, pid)), alpha = .04) + 
  geom_line(stat = 'smooth', method = 'lm', size = 1) + 
  theme_classic()
  
```

Well, look at that. The Demo.growth data has two time varying variables, `t`, and `c`. Just right for our purposes.

In the below `lavaan` code, I'll be using the notation from the diagram, except instead of "x" and "y", I'll use "t" and "c". I am explicitly specifying everything in the diagram, which is why in the call to `lavaan` I set a bunch of `auto` options to false. This is because often lavaan will try to automatically estimate things that you don't usually write out but often want estimated, like residuals. Because this model is unorthodox, I want to be as explicit as possible.

# Fitting a RI-CLPM

The lavaan code below uses syntax that can be found in their help docs for the [basic stuff](http://lavaan.ugent.be/tutorial/syntax1.html) as well as the more [advanced](http://lavaan.ugent.be/tutorial/syntax2.html) labeling and constraining.

```{r,lavaan ri-clpm}
riclpmModel <- 
'
#Note, the data contain t1-3 and c1-3
#Latent mean Structure with intercepts

kappa =~ 1*t1 + 1*t2 + 1*t3
omega =~ 1*c1 + 1*c2 + 1*c3

t1 ~ mu1*1 #intercepts
t2 ~ mu2*1
t3 ~ mu3*1
c1 ~ pi1*1
c2 ~ pi2*1
c3 ~ pi3*1

kappa ~~ kappa #variance
omega ~~ omega #variance
kappa ~~ omega #covariance

#laten vars for AR and cross-lagged effects
p1 =~ 1*t1 #each factor loading set to 1
p2 =~ 1*t2
p3 =~ 1*t3
q1 =~ 1*c1
q2 =~ 1*c2
q3 =~ 1*c3

#constrain autoregression and cross lagged effects to be the same across both lags.
p3 ~ alpha3*p2 + beta3*q2
p2 ~ alpha2*p1 + beta2*q1

q3 ~ delta3*q2 + gamma3*p2
q2 ~ delta2*q1 + gamma2*p1

p1 ~~ p1 #variance
p2 ~~ u2*p2
p3 ~~ u3*p3
q1 ~~ q1 #variance
q2 ~~ v2*q2
q3 ~~ v3*q3

p1 ~~ q1 #p1 and q1 covariance
p2 ~~ q2 #p2 and q2 covariance
p3 ~~ q3 #p2 and q2 covariance'

fit <- lavaan(riclpmModel, data = Demo.growth,
              int.ov.free = F,
              int.lv.free = F,
              auto.fix.first = F,
              auto.fix.single = F,
              auto.cov.lv.x = F,
              auto.cov.y = F,
              auto.var = F)
summary(fit)
```

I'm not sure why some variances are negative, except that this is probably an artificial data set. If you try this on your own real data and get the same problem, please let me know.

# References